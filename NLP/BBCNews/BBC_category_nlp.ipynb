{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# NLP (Natural Language Processing) with Python\n",
    "\n",
    "## Kaggle BBC News Group 20 data set \n",
    "\n",
    "Data set can be down load from <a href=\"https://www.kaggle.com/balatmak/newsgroup20bbcnews\">download</a>\n",
    "    \n",
    "**Requirements: You will need to have NLTK installed, along with downloading the corpus for stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below is the sample code to download library from NLTK\n",
    "\n",
    "! pip install nltk\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from above link and place into Dataset folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source data from public data set on BBC news articles. Source data from public data set on BBC news articles: D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006. [PDF] [BibTeX].\n",
    "\n",
    "http://mlg.ucd.ie/datasets/bbc.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset/bbc-text.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2225</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sport</td>\n",
       "      <td>us duo in first spam conviction a brother and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>511</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               text\n",
       "count      2225                                               2225\n",
       "unique        5                                               2126\n",
       "top       sport  us duo in first spam conviction a brother and ...\n",
       "freq        511                                                  2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>510</td>\n",
       "      <td>503</td>\n",
       "      <td>jobs growth still slow in the us the us create...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>386</td>\n",
       "      <td>369</td>\n",
       "      <td>howl helps boost japan s cinemas japan s box o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>417</td>\n",
       "      <td>403</td>\n",
       "      <td>debate needed  on donations cap a cap on donat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>511</td>\n",
       "      <td>504</td>\n",
       "      <td>bortolami predicts dour contest italy skipper ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>401</td>\n",
       "      <td>347</td>\n",
       "      <td>what high-definition will do to dvds first it ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text                                                            \\\n",
       "              count unique                                                top   \n",
       "category                                                                        \n",
       "business        510    503  jobs growth still slow in the us the us create...   \n",
       "entertainment   386    369  howl helps boost japan s cinemas japan s box o...   \n",
       "politics        417    403  debate needed  on donations cap a cap on donat...   \n",
       "sport           511    504  bortolami predicts dour contest italy skipper ...   \n",
       "tech            401    347  what high-definition will do to dvds first it ...   \n",
       "\n",
       "                    \n",
       "              freq  \n",
       "category            \n",
       "business         2  \n",
       "entertainment    2  \n",
       "politics         2  \n",
       "sport            2  \n",
       "tech             2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('category').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(20,5)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe8072b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing\n",
    "\n",
    "Our main issue with our data is that it is all in text format (strings). The classification algorithms that we've learned about so far will need some sort of numerical feature vector in order to perform the classification task. There are actually many methods to convert a corpus to a vector format. The simplest is the the bag-of-words approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "In this section we'll convert the raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "As a first step, let's write a function that will split a message into its individual words and return a list. We'll also remove very common words, ('the', 'a', etc..). To do this we will take advantage of the NLTK library. It's pretty much the standard library in Python for processing text and has a lot of useful features. We'll only use some of the basic ones here.\n",
    "\n",
    "Let's create a function that will process the string in the message column, then we can just use apply() in pandas do process all the text in the DataFrame.\n",
    "\n",
    "First removing punctuation. We can just take advantage of Python's built-in string library to get a quick list of all the possible punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's \"tokenize\" these messages. Tokenization is just the term used to describe the process of converting the normal text strings in to a list of tokens (words that we actually want).\n",
    "\n",
    "Let's see an example output on on column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [tv, future, hands, viewers, home, theatre, sy...\n",
       "1    [worldcom, boss, left, books, alone, former, w...\n",
       "2    [tigers, wary, farrell, gamble, leicester, say...\n",
       "3    [yeading, face, newcastle, fa, cup, premiershi...\n",
       "4    [ocean, twelve, raids, box, office, ocean, twe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure its working\n",
    "data['text'].head(5).apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show original dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Normalization and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32955\n"
     ]
    }
   ],
   "source": [
    "# Might take awhile...\n",
    "bow_transformer = CountVectorizer(analyzer=process).fit(data['text'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780 445 2225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(data['text'], data['category'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our model again and then predict off the test set. We will use SciKit Learn's pipeline capabilities to store a pipeline of workflow. This will allow us to set up all the transformations that we will do to the data for future use. Let's see an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function process at 0x1082D078>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.95      0.95        93\n",
      "entertainment       0.91      1.00      0.96        75\n",
      "     politics       0.95      0.91      0.93        87\n",
      "        sport       1.00      0.99      1.00       104\n",
      "         tech       0.98      0.97      0.97        86\n",
      "\n",
      "     accuracy                           0.96       445\n",
      "    macro avg       0.96      0.96      0.96       445\n",
      " weighted avg       0.96      0.96      0.96       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model and test with some real time BBC news\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bbc']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(pipeline, 'bbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business'], dtype='<U13')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc = load('bbc')\n",
    "\n",
    "text = \"Market leaders QuessNSE 5.00 % Corp and TeamLease told ET that they were betting on growing \\\n",
    "customer requirements like managing staff virtually, conducting interviews online,\\\n",
    "remote training and remote surveillance. The two companies are among the largest private sector employers in the country. \\\n",
    "The coronavirus pandemic disrupted the staffing sector as temporary staff were the first to be laid-off by companies to \\\n",
    "control cost.\"\n",
    "\n",
    "\n",
    "pred_value = bbc.predict([text])\n",
    "pred_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
